{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd8Zf39ByBkB96ov0OB9TE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaGha/C3D/blob/master/Copy_of_SN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6dFOovno9LD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "PCQA5qXJpUJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(X_axis, Y_axis):\n",
        "    pairImages = []\n",
        "    pairLabels = []\n",
        "\n",
        "    labels = np.unique(Y_axis)\n",
        "    numClasses = len(labels)\n",
        "    y2 = np.array(Y_axis)\n",
        "    idx = [np.where(y2 == labels[i])[0] for i in range(0, numClasses)]\n",
        "\n",
        "    for i in range(0, len(X_axis)):\n",
        " \t# grab the current image and label belonging to the current\n",
        "     \t# iteration\n",
        "         currentImage = X_axis[i]\n",
        "         label = np.where(labels == y2[i])\n",
        "         label =label[0][0]\n",
        "     \t# randomly pick an image that belongs to the *same* class\n",
        "     \t# label\n",
        "         idxB = np.random.choice(idx[label])\n",
        "         posImage = X_axis[idxB]\n",
        "     \t# prepare a positive pair and update the images and labels\n",
        "     \t# lists, respectively\n",
        "         pairImages.append([currentImage, posImage])\n",
        "         pairLabels.append([1])\n",
        "         # grab the indices for each of the class labels *not* equal to\n",
        "         # the current label and randomly pick an image corresponding\n",
        "         # to a label *not* equal to the current label\n",
        "         negIdx = np.where(labels != y2[i])[0]\n",
        "         negIdx = np.random.choice(negIdx)\n",
        "         idxC = np.random.choice(idx[negIdx])\n",
        "         negImage = X_axis[idxC]\n",
        "         # prepare a negative pair of images and update our lists\n",
        "         pairImages.append([currentImage, negImage])\n",
        "         pairLabels.append([0])\n",
        "\n",
        "    return (np.array(pairImages), np.array(pairLabels))\n"
      ],
      "metadata": {
        "id": "4GvcoAb1sRio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "    #import tensorflow.keras.backend\n",
        " \t# unpack the vectors into separate lists\n",
        "    (featsA, featsB) = vectors\n",
        " \t# compute the sum of squared distances between the vectors\n",
        "    sumSquared = keras.backend.sum(keras.backend.square(featsA - featsB), axis=1, keepdims=True)\n",
        " \t# return the euclidean distance between the vectors\n",
        "    return keras.backend.sqrt(keras.backend.maximum(sumSquared, keras.backend.epsilon()))"
      ],
      "metadata": {
        "id": "FV9NRaaqsVgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(H, plotPath):\n",
        " \t# construct a plot that plots and saves the training history\n",
        " \tplt.style.use(\"ggplot\")\n",
        " \tplt.figure()\n",
        " \tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        " \tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        " \tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        " \tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        " \tplt.title(\"Training Loss and Accuracy\")\n",
        " \tplt.xlabel(\"Epoch #\")\n",
        " \tplt.ylabel(\"Loss/Accuracy\")\n",
        " \tplt.legend(loc=\"lower left\")\n",
        " \tplt.savefig(plotPath)"
      ],
      "metadata": {
        "id": "C74e_2NZsu6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 'p2'\n",
        "a1= '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/' + p + '/data/'\n",
        "model = 'siamese_model-Base-p2-13-0.06-0.98.h5'\n",
        "useBaseModel = False\n"
      ],
      "metadata": {
        "id": "ByBPd3RctX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a= os.listdir(a1)\n",
        "modelSave = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/' + p + '/'\n",
        "# modelSave = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/' + p + '/'\n",
        "\n",
        "# split (a) to have the class name and file name\n",
        "class1 = []\n",
        "for x in a:\n",
        "    aa = x.split(\"_\")\n",
        "    b = aa[0]\n",
        "    class1.append(b)\n",
        "\n",
        "y = class1\n",
        "X = a\n",
        "df = pd.DataFrame({'FileName':a,\n",
        "                       'id': class1})\n",
        "print('X:')\n",
        "print(X)\n",
        "print('y:')\n",
        "print(y)\n",
        "\n",
        "df.to_csv('/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/Dataframes_of_files/df_id_ImgName_Siamese_11kHands.csv')\n",
        "\n",
        "df= pd.read_csv(r\"/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/Dataframes_of_files/df_id_ImgName_Siamese_11kHands.csv\")\n",
        "df = df.applymap(str)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Save the training data (X_train, y_train) to df\n",
        "df_train = pd.DataFrame({'FileName':X_train,\n",
        "                   'id': y_train})\n",
        "\n",
        "\n",
        "    # Save the testing data (X_test, y_test) to df\n",
        "df_test = pd.DataFrame({'FileName':X_test,\n",
        "                   'id': y_test})\n",
        "\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "# convert the images to arrays\n",
        "X_train_images = []\n",
        "for i in range(0,len(X_train)):\n",
        "        # load the image\n",
        "    image = Image.open(a1 + '/' + X_train[i])\n",
        "    image =  image.resize((224, 224))\n",
        "         # convert image to numpy array\n",
        "    data = asarray(image)\n",
        "    X_train_images.append(data)\n",
        "\n",
        "X_test_images = []\n",
        "for i in range(0,len(X_test)):\n",
        "    # load the image\n",
        "    image = Image.open(a1 + '/' + X_test[i])\n",
        "    image =  image.resize((224, 224))\n",
        "    # convert image to numpy array\n",
        "    data = asarray(image)\n",
        "    X_test_images.append(data)\n",
        "\n",
        "\n",
        "(pairTrain, labelTrain) = make_pairs(X_train_images, y_train)\n",
        "(pairTest, labelTest) = make_pairs(X_test_images, y_test)\n",
        "\n",
        "\n",
        "    # specify the shape of the inputs for our network\n",
        "IMG_SHAPE = (224, 224, 3)\n",
        "    # specify the batch size and number of epochs\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 30\n",
        "\n",
        "    #BASE_OUTPUT = \"output\"\n",
        "    # use the base output path to derive the path to the serialized\n",
        "    # model along with training history plot\n",
        "    # MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model.h5\"])\n",
        "    # PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "\n",
        "MODEL_PATH = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/' + p + '/siamese_model.h5'\n",
        "PLOT_PATH = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/' + p + '/plot.png'\n",
        "\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "    # import the necessary packages\n",
        "    # from tensorflow.keras.models import Model\n",
        "    # from tensorflow.keras.layers import Input\n",
        "    # from tensorflow.keras.layers import Dense\n",
        "    # from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "    # from tensorflow.keras.layers import Lambda\n",
        "    # from keras.callbacks import ModelCheckpoint\n",
        "    # from tensorflow.keras.applications import DenseNet201\n",
        "import matplotlib.pyplot as plt\n",
        "imgA = keras.layers.Input(shape=IMG_SHAPE)\n",
        "imgB = keras.layers.Input(shape=IMG_SHAPE)\n",
        "\n",
        "if useBaseModel:\n",
        "    featureExtractor = keras.applications.DenseNet169(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
        "    # or include_top=True and add it manulally\n",
        "    x = featureExtractor.output\n",
        "    pooledOutput = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = keras.layers.Dense(960)(pooledOutput)\n",
        "    featureExtractor = keras.models.Model(featureExtractor.input, outputs)\n",
        "else:\n",
        "    modelPath = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/selectedModels/' + p + '/'\n",
        "    featureExtractor = keras.models.load_model(modelPath + model)\n",
        "    featureExtractor.summary()\n",
        "    lastFC = featureExtractor.layers[-3]\n",
        "    featureExtractor= keras.models.Model(inputs=featureExtractor.input, outputs=lastFC.output)\n",
        "\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "\n",
        "    # finally, construct the siamese network\n",
        "distance = keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = keras.models.Model(inputs=[imgA, imgB], outputs=outputs)\n",
        "SGD = keras.optimizers.SGD(lr=0.01, nesterov=True, momentum=0.9)\n",
        "Adam = keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "EarlyStopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "LogFile = keras.callbacks.CSVLogger(modelSave + 'LogFile.csv' , separator=\",\", append=False)\n",
        "if useBaseModel:\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(modelSave + 'siamese_model-Base-'+ p +'-{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5',  monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "            save_weights_only=True, mode='max')\n",
        "else:\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(modelSave + 'siamese_model-Finetunning'+ p +'-{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5',  monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "    save_weights_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [ EarlyStopping, checkpoint, LogFile]\n",
        "\n",
        "model.summary()\n",
        "    # compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer= SGD , \tmetrics=[\"accuracy\"])\n",
        "    # train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        " \t[pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
        " \tvalidation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
        "    callbacks=callbacks_list,\n",
        " \tbatch_size=BATCH_SIZE,\n",
        " \tepochs=EPOCHS)\n",
        "\n",
        "    # serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save(modelSave + 'siamese_model.h5' )\n",
        "    # plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, PLOT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "sGAerbjIuNJM",
        "outputId": "92c500cb-7d4f-46b2-cad1-207b27086389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/p2/data/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-580695f5a87c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodelSave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# modelSave = '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/codes/output/' + p + '/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# split (a) to have the class name and file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mmfs1/storage/users/alghamdm/Training_validation_data/L_Hand_seg/p2/data/'"
          ]
        }
      ]
    }
  ]
}